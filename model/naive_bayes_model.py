# Naive Bayes Model Parameters
import numpy as np

classes_ = np.array([0, 1])
class_prior_ = np.array([0.6263736263736264, 0.37362637362637363])
theta_ = np.array([[-0.5623786506395008, -0.319431025694188, -0.5715435539351615, -0.5436367233917295, -0.3001143849933665, -0.4684009343304949, -0.5280319800970389, -0.5991236255260749, -0.26360218253949447, -0.0042741397183190186, -0.43140134059211865, 0.005146002439510599, -0.42227719954768705, -0.41230631423713776, 0.043755772402563335, -0.22007592060050085, -0.17568950623714627, -0.3107569658033681, -0.0049664474204123244, -0.054327832994882086, -0.600563824722739, -0.3604197118733895, -0.604640971754723, -0.5651600865990206, -0.3333653332325704, -0.4533913914679276, -0.4966967485372083, -0.6072865125022034, -0.32917833657607304, -0.25185778375140305], [0.942811267248575, 0.5355167195461389, 0.9581759580677718, 0.9113909774508401, 0.503132939547705, 0.7852603899070058, 0.885230084280331, 1.0044131369113607, 0.441921306022094, 0.0071654695277710385, 0.7232316592279636, -0.008627121736826806, 0.7079353051240626, 0.6912194091622607, -0.07335526549841535, 0.3689508080655454, 0.29453828986815705, 0.5209749132585875, 0.008326103028338491, 0.09107901413847877, 1.0068275885057678, 0.6042330463759772, 1.0136628055887984, 0.9474742628277687, 0.5588771763016618, 0.7600973327550543, 0.8326974901947314, 1.018097976841928, 0.5518577995540033, 0.4222321668773533]])
var_ = np.array([[0.2476542418859027, 0.8430059887116859, 0.22909143016280148, 0.13982585759031635, 0.8723790974515087, 0.365798055868126, 0.30665884233319257, 0.15396506830189488, 0.7843194772308979, 0.8900111513324834, 0.15832954975501873, 1.1545382225073653, 0.13739081934707847, 0.03577962077698969, 0.9250594495976872, 0.8633459734839886, 1.2351224265132905, 0.8312633842149314, 0.6371124942398131, 1.265178091273824, 0.1634012840414853, 0.7704185342550189, 0.15773201544817692, 0.0797201409168635, 0.7570406321154398, 0.35095256944241005, 0.48194370022173877, 0.30121774674413415, 0.40579233442212964, 0.5956369704492844], [0.8421755244045048, 0.8053570332159413, 0.8266650872386924, 1.1159575346978652, 0.809812504662881, 1.078770328733127, 0.9113039647589107, 0.8077392925755267, 1.0497961940596805, 1.1843111023299613, 1.5759686172397012, 0.7408023954657461, 1.6460215888330099, 1.8537087104974415, 1.1170449200140915, 1.0117745713809472, 0.4673240790790965, 0.8495705326497932, 1.6082595577769438, 0.542193219725639, 0.7841671237705954, 0.8020115027898755, 0.7716231589528365, 1.1096400042235606, 0.908660262766375, 1.1657393877657358, 0.7615229062333095, 0.5166872376492058, 1.5099650139094176, 1.3932802681637364]])

def predict_proba(X):
    """Predict class probabilities"""
    X = np.array(X)
    if X.ndim == 1:
        X = X.reshape(1, -1)
    
    joint_log_likelihood = []
    for i in range(len(classes_)):
        jointi = np.log(class_prior_[i])
        n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * var_[i, :]))
        n_ij -= 0.5 * np.sum(((X - theta_[i, :]) ** 2) / var_[i, :], axis=1)
        joint_log_likelihood.append(jointi + n_ij)
    
    joint_log_likelihood = np.array(joint_log_likelihood).T
    log_prob_x = np.logaddexp.reduce(joint_log_likelihood, axis=1)
    log_prob = joint_log_likelihood - np.atleast_2d(log_prob_x).T
    return np.exp(log_prob)

def predict(X):
    """Predict class labels"""
    proba = predict_proba(X)
    return classes_[np.argmax(proba, axis=1)] if proba.ndim > 1 else classes_[np.argmax(proba)]
